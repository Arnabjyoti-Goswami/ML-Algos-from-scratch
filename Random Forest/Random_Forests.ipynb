{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implement the Random Forest Model using the previously implemented Decision Tree Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GJ4rcAParOLN"
      },
      "outputs": [],
      "source": [
        "from DecisionTree import DecisionTree, most_common_element # use the previously implemented DecisionTree algorithm\n",
        "import numpy as np\n",
        "\n",
        "class RandomForest:\n",
        "  def __init__(self, num_trees=10, max_depth=10, min_examples_for_split=2, num_features=None):\n",
        "    self.num_trees = num_trees\n",
        "    self.max_depth = max_depth\n",
        "    self.min_examples_for_split = min_examples_for_split\n",
        "    self.num_features = num_features\n",
        "    self.trees = []\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    # Make a list of trees and train each tree\n",
        "    self.trees = []\n",
        "    for _ in range(self.num_trees):\n",
        "      tree = DecisionTree(min_examples_for_split = self.min_examples_for_split, max_depth = self.max_depth, num_features = self.num_features)\n",
        "      X_sample, y_sample = self._bootstrap_examples(X, y)\n",
        "      tree.fit(X_sample, y_sample)\n",
        "      self.trees.append(tree)\n",
        "\n",
        "  def _bootstrap_examples(self, X, y):\n",
        "    num_examples = X.shape[0]\n",
        "    # Create num_example number of random indices in the range of (0, num_examples)\n",
        "    # This is a random subset and not the whole dataset because its with replacement so that each example maybe repeated\n",
        "    indices = np.random.choice(num_examples, num_examples, replace=True)\n",
        "    return X[indices], y[indices]\n",
        "\n",
        "  def _most_common_label(self, y):\n",
        "    return most_common_element(y)\n",
        "\n",
        "  def predict(self, X):\n",
        "    # First store all the predictions for the examples from all the trees\n",
        "    tree_predictions = np.array([tree.predict(X) for tree in self.trees])\n",
        "    tree_predictions = np.swapaxes(tree_predictions, 0, 1)\n",
        "    # Then get the majority voted label from all the trees, which is the prediction of the random forest\n",
        "    y_pred = np.array([most_common_element(pred) for pred in tree_predictions])\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifI9ij7zOSRL"
      },
      "source": [
        "# Load in a dataset from sklearn and partition it into training and testing datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jJV-WvzKO3a-"
      },
      "outputs": [],
      "source": [
        "rs = 1234 # random seed for reproducibility of results\n",
        "np.random.seed(rs)\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "breast_cancer_dataset = datasets.load_breast_cancer()\n",
        "X = breast_cancer_dataset.data\n",
        "y = breast_cancer_dataset.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNX3172iPxLH"
      },
      "source": [
        "# Train the implemented Random Forest model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HnCCgQrdOkXo"
      },
      "outputs": [],
      "source": [
        "model = RandomForest(num_trees=20)\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYcSokHPONha"
      },
      "source": [
        "# Test the model on the test dataset obtained from the previous train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wjEqWRDOOM-p"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_test, y_pred):\n",
        "  acc = np.sum(y_test == y_pred) / len(y_test)\n",
        "  acc *= 100\n",
        "  acc = round(acc, 2)\n",
        "  return acc\n",
        "\n",
        "def calculate_metrics(y_test, y_pred):\n",
        "  true_positives = np.sum(np.logical_and(y_test == 1, y_pred == 1))\n",
        "  false_positives = np.sum(np.logical_and(y_test == 0, y_pred == 1))\n",
        "  false_negatives = np.sum(np.logical_and(y_test == 1, y_pred == 0))\n",
        "  precision = true_positives / (true_positives + false_positives) if true_positives + false_positives > 0 else 0\n",
        "  recall = true_positives / (true_positives + false_negatives) if true_positives + false_negatives > 0 else 0\n",
        "  f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
        "  confusion_matrix = np.array([[true_positives, false_positives], [false_negatives, len(y_test) - true_positives]])\n",
        "  return precision, recall, f1_score, confusion_matrix\n",
        "\n",
        "def print_confusion_matrix(conf_matrix):\n",
        "  true_positives, false_positives, false_negatives, true_negatives = conf_matrix.ravel()\n",
        "  print(f\"                    Actual Positive    | Actual Negative\")\n",
        "  print(f\"Predicted Positive |       {true_positives} (TP)     |    {false_positives} (FP)\")\n",
        "  print(f\"Predicted Negative |       {false_negatives} (FN)     |    {true_negatives} (TN)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHAjIMDrOWWj",
        "outputId": "663f8489-5ffa-4b92-e275-2962a959ed48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 93.86%\n",
            "Precision: 0.9428571428571428\n",
            "Recall: 0.9565217391304348\n",
            "F1 Score: 0.9496402877697843\n",
            "Confusion Matrix:\n",
            "                    Actual Positive    | Actual Negative\n",
            "Predicted Positive |       66 (TP)     |    4 (FP)\n",
            "Predicted Negative |       3 (FN)     |    48 (TN)\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "acc = accuracy(y_test, y_pred)\n",
        "precision, recall, f1_score, confusion_matrix = calculate_metrics(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {acc}%\")\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1_score)\n",
        "print(\"Confusion Matrix:\")\n",
        "print_confusion_matrix(confusion_matrix)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
