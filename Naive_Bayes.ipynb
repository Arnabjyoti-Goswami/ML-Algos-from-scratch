{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implement the Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "34dxR2vlI0z6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ogGwWWqEBo6x"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class NaiveBayes:\n",
        "  def fit(self, X, y):\n",
        "    num_examples, num_features = X.shape\n",
        "    self._classes = np.unique(y)\n",
        "    num_classes = len(self._classes)\n",
        "    # Initialize mean, variance and priors as zeroes\n",
        "    self._means = np.zeros((num_classes, num_features))\n",
        "    self._variances = np.zeros((num_classes, num_features))\n",
        "    self._priors = np.zeros(num_classes)\n",
        "    # Calculate the mean, variance and priors for each class and store them in the class\n",
        "    for i, c in enumerate(self._classes):\n",
        "      X_c = X[y==c] # All examples in X with class 'c'\n",
        "      self._means[i, :] = X_c.mean(axis=0)\n",
        "      self._variances[i, :] = X_c.var(axis=0)\n",
        "      self._priors[i] = X_c.shape[0] / num_examples # prior probability, i.e., frequency of each class\n",
        "\n",
        "  def predict(self, X):\n",
        "    return np.array([self._predict(x) for x in X])\n",
        "\n",
        "  def _predict(self, x):\n",
        "    # Calculate posterior probability for each class\n",
        "    posteriors = []\n",
        "    for i in range(len(self._classes)):\n",
        "      posteriors.append( np.log(self._priors[i]) + np.sum(np.log(self._pdf(i, x))) )\n",
        "    # Return the index of the class with the highest posterior probability\n",
        "    return self._classes[np.argmax(posteriors)]\n",
        "\n",
        "  def _pdf(self, class_index, x):\n",
        "    # Implement the Probability Density Function (PDF) of a Gaussian Distribution, P(x|c)\n",
        "    # for each each unique class 'c' present in 'y'.\n",
        "    mean = self._means[class_index]\n",
        "    variance = self._variances[class_index]\n",
        "    numerator = np.exp(-((x - mean) ** 2) / (2 * variance)) + 1e-9 # Avoid taking natural log of 0 warning in the _predict function\n",
        "    denominator = np.sqrt(2 * np.pi * variance)\n",
        "    return numerator / denominator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the model"
      ],
      "metadata": {
        "id": "v4odknLLIwRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = datasets.load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "model = NaiveBayes()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "gXHXQrAdIvWQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_test, y_pred):\n",
        "  acc = np.sum(y_test == y_pred) / len(y_test)\n",
        "  acc *= 100\n",
        "  acc = round(acc, 2)\n",
        "  return acc\n",
        "\n",
        "def calculate_metrics(y_test, y_pred):\n",
        "  true_positives = np.sum(np.logical_and(y_test == 1, y_pred == 1))\n",
        "  false_positives = np.sum(np.logical_and(y_test == 0, y_pred == 1))\n",
        "  false_negatives = np.sum(np.logical_and(y_test == 1, y_pred == 0))\n",
        "  precision = true_positives / (true_positives + false_positives) if true_positives + false_positives > 0 else 0\n",
        "  recall = true_positives / (true_positives + false_negatives) if true_positives + false_negatives > 0 else 0\n",
        "  f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
        "  confusion_matrix = np.array([[true_positives, false_positives], [false_negatives, len(y_test) - true_positives]])\n",
        "  return precision, recall, f1_score, confusion_matrix\n",
        "\n",
        "def print_confusion_matrix(conf_matrix):\n",
        "  true_positives, false_positives, false_negatives, true_negatives = conf_matrix.ravel()\n",
        "  print(f\"                    Actual Positive    | Actual Negative\")\n",
        "  print(f\"Predicted Positive |       {true_positives} (TP)     |    {false_positives} (FP)\")\n",
        "  print(f\"Predicted Negative |       {false_negatives} (FN)     |    {true_negatives} (TN)\")"
      ],
      "metadata": {
        "id": "OJgzGN6SJ46Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy(y_test, y_pred)\n",
        "precision, recall, f1_score, confusion_matrix = calculate_metrics(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {acc}%\")\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1_score)\n",
        "print(\"Confusion Matrix:\")\n",
        "print_confusion_matrix(confusion_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-GqbsuXJ5uK",
        "outputId": "49749729-c69e-4e0d-a2ff-d25ed0c483b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 88.6%\n",
            "Precision: 0.8783783783783784\n",
            "Recall: 0.9420289855072463\n",
            "F1 Score: 0.9090909090909092\n",
            "Confusion Matrix:\n",
            "                    Actual Positive    | Actual Negative\n",
            "Predicted Positive |       65 (TP)     |    9 (FP)\n",
            "Predicted Negative |       4 (FN)     |    49 (TN)\n"
          ]
        }
      ]
    }
  ]
}